# ğŸ¤– RAG Chatbot Backend vá»›i Gemini API

Há»‡ thá»‘ng backend RAG (Retrieval-Augmented Generation) chatbot sá»­ dá»¥ng Google Gemini API, Ä‘Æ°á»£c tá»‘i Æ°u hÃ³a cho deployment trÃªn Vercel.

## ğŸš€ TÃ­nh nÄƒng

- **RAG System**: TÃ¬m kiáº¿m vÃ  sá»­ dá»¥ng context tá»« documents Ä‘á»ƒ tráº£ lá»i
- **Gemini API Integration**: Sá»­ dá»¥ng Google Gemini 1.5 Flash model
- **Document Processing**: Há»— trá»£ PDF, DOCX, TXT files
- **Vector Search**: Semantic search trong documents
- **Conversation Memory**: LÆ°u trá»¯ lá»‹ch sá»­ chat
- **Secure API Key**: Sá»­ dá»¥ng Vercel environment variables
- **Rate Limiting**: Báº£o vá»‡ khá»i spam requests
- **Comprehensive Logging**: Winston logging system

## ğŸ“ Cáº¥u trÃºc dá»± Ã¡n

```
backend/
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ index.js         # Main API entry point
â”‚   â”œâ”€â”€ chat.js          # Chat endpoint
â”‚   â””â”€â”€ documents.js     # Document upload endpoint
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ geminiService.js # Gemini API integration
â”‚   â”œâ”€â”€ ragService.js    # RAG logic
â”‚   â””â”€â”€ vectorService.js # Vector storage & search
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ logger.js        # Winston logging
â”‚   â”œâ”€â”€ textProcessor.js # Text processing utilities
â”‚   â””â”€â”€ documentParser.js # Document parsing
â”œâ”€â”€ middleware/
â”‚   â””â”€â”€ errorHandler.js  # Error handling
â”œâ”€â”€ package.json
â”œâ”€â”€ vercel.json          # Vercel configuration
â””â”€â”€ .env.example         # Environment variables template
```

## ğŸ”§ API Endpoints

### Chat
- `POST /chat` - Chat vá»›i RAG system
- `GET /chat/history/:conversationId` - Láº¥y lá»‹ch sá»­ chat
- `DELETE /chat/history/:conversationId` - XÃ³a lá»‹ch sá»­ chat

### Documents
- `POST /documents/upload` - Upload documents
- `GET /documents` - Láº¥y danh sÃ¡ch documents
- `DELETE /documents/:documentId` - XÃ³a document
- `POST /documents/search` - TÃ¬m kiáº¿m trong documents

### System
- `GET /` - API info
- `GET /health` - Health check

## ğŸ› ï¸ Setup vÃ  Deployment

### 1. CÃ i Ä‘áº·t Dependencies
```bash
cd backend
npm install
```

### 2. Environment Variables
Trong Vercel Dashboard â†’ Settings â†’ Environment Variables:

**Required:**
```
GEMINI_API_KEY = AIzaSyCM4LsYsE6adRq1A5u4ros6yRJpBG7YMSw
```

**Optional:**
```
GEMINI_MODEL = gemini-1.5-flash
NODE_ENV = production
MAX_DOCUMENTS = 1000
CHUNK_SIZE = 500
SIMILARITY_THRESHOLD = 0.7
```

### 3. Deploy lÃªn Vercel
```bash
# Vercel CLI
npm install -g vercel
vercel --prod

# Hoáº·c Git Integration
# Push code â†’ Auto deploy
```

## ğŸ“ Usage Examples

### Chat Request
```bash
curl -X POST https://your-backend.vercel.app/chat \
  -H "Content-Type: application/json" \
  -d '{
    "message": "What is artificial intelligence?",
    "useRag": true
  }'
```

### Upload Document
```bash
curl -X POST https://your-backend.vercel.app/documents/upload \
  -F "documents=@document.pdf"
```

### Health Check
```bash
curl https://your-backend.vercel.app/health
```

## ğŸ”’ Security Features

- âœ… Secure API key handling via Vercel environment variables
- âœ… Rate limiting (100 requests/15 minutes)
- âœ… Input validation
- âœ… File type restrictions
- âœ… Error message sanitization
- âœ… CORS configuration
- âœ… Helmet security headers

## ğŸ§  RAG System

1. **Document Upload**: Parse vÃ  chia nhá» documents thÃ nh chunks
2. **Vector Generation**: Táº¡o embeddings cho má»—i chunk
3. **Similarity Search**: TÃ¬m chunks liÃªn quan Ä‘áº¿n user query
4. **Context Injection**: ThÃªm relevant context vÃ o Gemini prompt
5. **Response Generation**: Gemini táº¡o response dá»±a trÃªn context

## ğŸ“Š Monitoring

- **Health Endpoint**: `/health` - Check system status
- **Logs**: Winston logging vá»›i different levels
- **Error Tracking**: Comprehensive error handling
- **Performance**: Request timing vÃ  memory usage

## ğŸ”§ Configuration

Táº¥t cáº£ configuration thÃ´ng qua environment variables:

```bash
# Core
GEMINI_API_KEY=xxx        # Required
GEMINI_MODEL=gemini-1.5-flash

# RAG Settings  
MAX_DOCUMENTS=1000        # Max documents in memory
CHUNK_SIZE=500           # Text chunk size
CHUNK_OVERLAP=50         # Overlap between chunks
MAX_CONTEXT_LENGTH=4000  # Max context for Gemini
SIMILARITY_THRESHOLD=0.7 # Min similarity for RAG

# System
NODE_ENV=production
LOG_LEVEL=info
FRONTEND_URL=*
```

## ğŸš€ Performance

- **Serverless**: Tá»± Ä‘á»™ng scale vá»›i Vercel
- **In-Memory Storage**: Fast access (sáº½ reset khi function restart)
- **Optimized Chunking**: Efficient text processing
- **Rate Limiting**: Prevent abuse
- **Compression**: Gzip compression enabled

## ğŸ“ˆ Scaling Considerations

Hiá»‡n táº¡i sá»­ dá»¥ng in-memory storage. Äá»ƒ scale production:

1. **Database**: ThÃªm PostgreSQL/MongoDB cho persistent storage
2. **Vector Database**: Sá»­ dá»¥ng Pinecone/Weaviate cho large-scale vector search
3. **Caching**: Redis cho conversation caching
4. **Queue System**: Background processing cho document upload

## ğŸ†˜ Troubleshooting

### Common Issues:

1. **API Key Error**: Kiá»ƒm tra Vercel environment variables
2. **Timeout**: TÄƒng maxDuration trong vercel.json
3. **Memory Issues**: Giáº£m MAX_DOCUMENTS hoáº·c CHUNK_SIZE
4. **Upload Fails**: Kiá»ƒm tra file size vÃ  type

### Debug Commands:
```bash
# Local development
npm run dev

# Check logs
vercel logs

# Test health
curl https://your-app.vercel.app/health
```

---

**Built with â¤ï¸ for FTC Team**